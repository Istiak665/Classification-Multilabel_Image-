{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "26e8d81d8973495291d95f52deec6aa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f23a6b9e12d343c8979e000f4ec301c5",
              "IPY_MODEL_91b8bf1411ff4ce2b9bdb1b7ac5f8194",
              "IPY_MODEL_d074268ad4a44012ac39cea7a1ca85b9"
            ],
            "layout": "IPY_MODEL_0133be5fe5304555baa6ac4e121ed75e"
          }
        },
        "f23a6b9e12d343c8979e000f4ec301c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3866a36370c047beaaa92ef866d0cfa1",
            "placeholder": "​",
            "style": "IPY_MODEL_6792fb5fd1e549178571326f15396416",
            "value": "100%"
          }
        },
        "91b8bf1411ff4ce2b9bdb1b7ac5f8194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e11a864a0ae34f15a15ec571eadbcff1",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ecd2efa32191450b8cadc86e663e0f00",
            "value": 10
          }
        },
        "d074268ad4a44012ac39cea7a1ca85b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33e645dc598e441d9202f3c81ba1fb71",
            "placeholder": "​",
            "style": "IPY_MODEL_4ceafc80f3664962a61ab134c14cec79",
            "value": " 10/10 [00:19&lt;00:00,  1.83s/it]"
          }
        },
        "0133be5fe5304555baa6ac4e121ed75e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3866a36370c047beaaa92ef866d0cfa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6792fb5fd1e549178571326f15396416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e11a864a0ae34f15a15ec571eadbcff1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecd2efa32191450b8cadc86e663e0f00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33e645dc598e441d9202f3c81ba1fb71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ceafc80f3664962a61ab134c14cec79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import Necessary Libraries"
      ],
      "metadata": {
        "id": "u2KhRps79a5B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8DVSuHS69BuV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, random_split, DataLoader\n",
        "from torchvision import datasets ,models , transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Directories and Hyperparameters"
      ],
      "metadata": {
        "id": "DE2oQ6QC9jrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file = (\"/content/drive/MyDrive/Construction Equipment Activity/Feature Extraction/audio/data.csv\")\n",
        "imagedir = (\"/content/drive/MyDrive/Construction Equipment Activity/Feature Extraction/audio/bulldozer_dump_truck\")\n",
        "# Let's define epoch numbers\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 10"
      ],
      "metadata": {
        "id": "fDl11YyZ9pQD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create custom Dataset Class"
      ],
      "metadata": {
        "id": "pt0JYDqJ93Pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.root_dir, self.data.iloc[idx, 0])\n",
        "        image = Image.open(img_name)\n",
        "        label = self.data.iloc[idx, 2:]\n",
        "        label = torch.tensor(label.values.astype(np.float32))\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "4JcllHk098fP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Transformation"
      ],
      "metadata": {
        "id": "b39PLGZ59_-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((28, 28)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "metadata": {
        "id": "HNbuMNOO9_fh"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create dataset object and print"
      ],
      "metadata": {
        "id": "p2N-pQBI-Lv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fulldataset = CustomDataset(csv_file, imagedir, transform=transform)\n",
        "print(fulldataset)\n",
        "\n",
        "image, label=fulldataset[0]\n",
        "print(image.shape, label.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2wvkCbE-QK3",
        "outputId": "31f90739-dde7-4e3e-9d9a-c6b20896df52"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<__main__.CustomDataset object at 0x7f87c55aefd0>\n",
            "torch.Size([3, 28, 28]) torch.Size([2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the full datset for train and test"
      ],
      "metadata": {
        "id": "7D_IE96g-Ynb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Test Split random\n",
        "train_size = int(len(fulldataset) * 0.8)\n",
        "test_size = len(fulldataset) - train_size\n",
        "traindataset ,testdataset  = random_split( fulldataset , [train_size  ,test_size])\n",
        "\n",
        "print(train_size)\n",
        "print(test_size)\n",
        "print(traindataset)\n",
        "print(testdataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jP-2bwlU-cmi",
        "outputId": "480eabca-cb44-4565-a16f-bb165b0b2b00"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "2\n",
            "<torch.utils.data.dataset.Subset object at 0x7f8868364550>\n",
            "<torch.utils.data.dataset.Subset object at 0x7f87c424b910>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Test dataloader"
      ],
      "metadata": {
        "id": "uJfI_jK_-i9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn datasets into iterables (batches)\n",
        "train_dataloader = DataLoader(dataset=traindataset,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(dataset=testdataset,\n",
        "                             batch_size=BATCH_SIZE,\n",
        "                             shuffle=False)\n",
        "\n",
        "train_dataloader, test_dataloader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AW_ZjeUe-mnf",
        "outputId": "dc728381-79ff-42a6-f070-c24414c8d12e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7f87c4d1df40>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7f87c4d1df70>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check the images and labels"
      ],
      "metadata": {
        "id": "81nVzNBz-uJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check\n",
        "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
        "test_features_batch, test_labels_batch = next(iter(test_dataloader))\n",
        "\n",
        "print(train_features_batch.shape, train_labels_batch.shape)\n",
        "print(test_features_batch.shape, test_labels_batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7nxdXqf-yn5",
        "outputId": "e54cd51a-e6da-4d94-b543-645757d22413"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 3, 28, 28]) torch.Size([8, 2])\n",
            "torch.Size([2, 3, 28, 28]) torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot and show the images"
      ],
      "metadata": {
        "id": "omS01CSf-3nF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have already created a data loader called 'train_loader'\n",
        "# and that it returns a batch of images and labels\n",
        "images, labels = next(iter(train_dataloader))\n",
        "\n",
        "# Take the first image from the batch\n",
        "img = images[7]\n",
        "\n",
        "# Convert the tensor to a numpy array\n",
        "img = img.numpy()\n",
        "\n",
        "# Transpose the image so that it has the format (height, width, channels)\n",
        "img = np.transpose(img, (1, 2, 0))\n",
        "\n",
        "# Plot the image\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "6w7eRij--8tI",
        "outputId": "123a8e82-1da9-46de-aea4-50faff403dd8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVvklEQVR4nO3dX4wk1XUG8O/U1FaaZpjMDhuW5Z9xLCILRQpORiiSUURkxcK8gF+QUWIRCWX9YCRb8kMQeTCPKIpt+SGytA7I68jBsmQjeECJCbKEeLEY8AaWPwkYLbDLsstmMp6dNE1vbZ08TGMNMPd8Q1dPd4f7/aTVzPSdqrpdVad7ts8995q7Q0Q+/oppd0BEJkPBLpIJBbtIJhTsIplQsItkopzowS7Y59XCVcn2pom3j/IGc+Rlaw95pgXZ3oK2tvmM8+fj9oYcIOx7y87RY0cnBsDv7Elf1PPn4533z83FxybXzD3duYZkoc7X8b7n4q7toG+jtQHAu+/009v234SfW9v2ibcKdjO7CcB3AcwB+Cd3vy/6/WrhKnz6L59Mtq9vxMeLXgwWF+JtL12K27vd+JUmOlE1eZEizVjbiO+MwSDevttJt9XkpmUGZPuK3EF/cFkv2ba2Fu/8hTfji7rQjY89aNLntdePr8rqWty+uBBfs+iaAPG93E/HMgDg2NGX0tv+6q+SbSP/GW9mcwD+EcAXAFwL4HYzu3bU/YnI7mrzf/brAbzi7q+6+wDAjwHcMp5uici4tQn2ywG8seXn48PH3sfMDprZipmt1O+caXE4EWlj1z+Nd/dD7r7s7svlBft2+3AiktAm2E8AuHLLz1cMHxORGdQm2J8CcI2ZfdLMKgBfAvDIeLolIuM2curN3WszuwvAv2Ez9faAuz8fHqw0LC1VyfaqE7/2hKm3+ThVculSnObppLsFACiK9P7ZK2YdpIAAYKEbt/cH8WVa6I6eX2Optd4g7ht77pcspM9bt4y3Xm/i/FWniq95lOteT2cEAQAL8+1Sa91O3LcovcbO+VvBzTqw9NiCVnl2d38UwKNt9iEik6HhsiKZULCLZELBLpIJBbtIJhTsIplQsItkYqL17GZxSSTLXUaJdlZqGZU7AkAXccK5DPLsDdl3Vcb77pIcf3/A8snBGADycl6Q13uWy2bPvRM8914RX7SKHJv1rQx2P6jZmA527LCZ3o/hEAJyzaJjR9XSemcXyYSCXSQTCnaRTCjYRTKhYBfJhIJdJBMTTb3B4zJVNpU0gjRPzaZ4JViKqlNGqTeSAiL77lbxdKKrTTyNahX0LUp9ATz9xd4P2FmfL9PPrSH5q0sX4ml1o+cNkNJiUlbcZeXWpDSYpQWj0CvIWY1OW1Dhqnd2kVwo2EUyoWAXyYSCXSQTCnaRTCjYRTKhYBfJxMRLXKNSUVYWGOWrWZ68T1ZCrVmZadA232HlsWTfZKpoNhU1K89toyzIFNwk171YppfmbYq4prlbkaV5yXtVVPrLyoo7JNddBfsG4vt88/jpdja9975geu5TwVLSemcXyYSCXSQTCnaRTCjYRTKhYBfJhIJdJBMKdpFMTDTPPlcAC93R684Xgnw2y0VHOVcgzntuHjudaW+bc91o4qRvl05Fne4bezUvq3jfbPxCN6hXB4BFnEkfm+TZN7qLYTur+46u+aBuN7aB1dJXZHxCtP9BE/ft9U560MicebKtVbCb2TEAZwGcB1C7+3Kb/YnI7hnHO/ufu3v65VtEZoL+zy6SibbB7gB+bmZPm9nB7X7BzA6a2YqZrfQ33m55OBEZVds/429w9xNmdgmAx8zsJXd/YusvuPshAIcA4OKr/iT96YGI7KpW7+zufmL49TSAhwBcP45Oicj4jRzsZnahmV303vcAPg/g6Lg6JiLj1ebP+P0AHrLNiapLAP/i7v8abVDNNbhqMcjLkpeeMsirsuw9y4t2SzJHeZA3bZPvBXjN+Go/vkxxnT953gV73mT8Qbketu/rvZlsK5q4Xn2xc1nYzgVLWZN6dpqHJzdrdK8CQBkNYCDLSUdLUUfzxo8c7O7+KoA/GnV7EZkspd5EMqFgF8mEgl0kEwp2kUwo2EUyMeGppB2doKSSLdkcpahYKeZC2Qvb50nqbaMOyjFbv2TGO+iQvg2CVE3DLjFJSRaknaWoorRkbxCXuK4ibmdpwei0NqSEla0Azi45ux/bXLPeINg2GKOqd3aRTCjYRTKhYBfJhIJdJBMKdpFMKNhFMqFgF8nERPPshTk6Qa68JFMmR+WaLG/KEp8DciqiY9dkW9a3Hlsvmhh9cm5eAkvPa4s7qKBLdMd9q8mUy1GOf0CeFxs/wMaELAbTPW/uP9220I2n5+6MWOKqd3aRTCjYRTKhYBfJhIJdJBMKdpFMKNhFMqFgF8nExOvZq6A2O8rBbwrypiC5apIYbUi2OppyudfEdddsWeOS9L1P6rrno7ELIMs9F3Hf2DTZ3SKeJyAa38CWNabTMZPz2kTHJnnymkyxzcYA9AbxNV3spvfPpjWPlg+fs2D67HCvIvKxoWAXyYSCXSQTCnaRTCjYRTKhYBfJhIJdJBMTzbPvsRqXdlaT7RVI3jToLqtt7pB8MMtHs/Y2mmgNXgA9dMP26LxVTXxOK5JPZnOYN+T9Ijr+UpG+FwDg6vn0cs8Az8O3qfOvydgHNv6g34m3b3M/LXXS93KU/6fv7Gb2gJmdNrOjWx5bMrPHzOzl4de9H7XDIjJZO/kz/gcAbvrAY3cDeNzdrwHw+PBnEZlhNNjd/QkAH/x76xYAh4ffHwZw63i7JSLjNuoHdPvd/eTw+7cA7E/9opkdNLMVM1s5+5u1EQ8nIm21/jTe3R1Acjk5dz/k7svuvnzR7y62PZyIjGjUYD9lZgcAYPj19Pi6JCK7YdRgfwTAHcPv7wDw8Hi6IyK7hebZzexBADcC2GdmxwF8E8B9AH5iZncCeA3AbTs5WIEGXaRzhAWpby6inDF52aoQ55NZe1mnj92QCdCjumqA57Kr4JwBQNmkzxur8+/U8b5Z36vgvADA/EY6V95gMdx2YX4jbC/INYtuCjr/ARl/wPLs8+R+jKZXKEkcdLGebIv6RYPd3W9PNH2ObSsis0PDZUUyoWAXyYSCXSQTCnaRTCjYRTIx2SWbcR7zzVrQHqsaMm1xeOw4VVINSHorSFGx1FuUGgNAl5Pul/NhexX1jZzVziCdxtmJgpRqdtbT462KMk6tlb14Cu1BSdqLdGlwSbYt6/h5sWW6yxZpwYIcO+qbuaaSFsmegl0kEwp2kUwo2EUyoWAXyYSCXSQTCnaRTEw0z74pKMFr4txkd7CWbKuLuGRxUMbTMbPto3JKlsOn0w4H+WCA963TRCWPMda3qLQX4GMM2ryf8NLh0ad77pAxG2SFb/qs2kwVzXL4RRkc3Sy93agdEpH/XxTsIplQsItkQsEukgkFu0gmFOwimVCwi2Rionl2RxHmlIsmfu3ZKJfSjeRliy3By3LZTbAUbkNqoztNXLc9KOLtWd/jevc4YVyTE1eS8Qms7818enwCy6Oz6Z5rsn20jDer82d5dva8ByDnJTg+m7eB9S1F7+wimVCwi2RCwS6SCQW7SCYU7CKZULCLZELBLpKJiebZ9zR9XNZ7JdneGZB5xKN2lnMl7exVr7vxVrDvOKdakDp9lqdvyjjfHNWcl32y7DFppzXlnTgPX55+Pdh3/Ly6l8Vz2rOxEWWdPu+DivSbzfVPkt11i2vK7pcrBult9zTvpvcb7hWAmT1gZqfN7OiWx+41sxNmdmT472a2HxGZrp38Gf8DADdt8/h33P264b9Hx9stERk3Guzu/gSA1Qn0RUR2UZsP6O4ys2eHf+bvTf2SmR00sxUzW/mf9fj/hyKye0YN9u8B+BSA6wCcBPCt1C+6+yF3X3b35b0L8QKFIrJ7Rgp2dz/l7ufdvQHwfQDXj7dbIjJuIwW7mR3Y8uMXARxN/a6IzAaaZzezBwHcCGCfmR0H8E0AN5rZdQAcwDEAX9nJwYqmxnyQr2a58qi9IHnRDpn/nOVNo5wwm++e7bsga8M3pCY9Wt+9JnnwzsYZsuv4mvSLxbAdQT6Z5dlZe7Qu/eb2Qd/Z+AFyzcomvp+qAVvfPX1d+tVCuO16MMdAY3PJNhrs7n77Ng/fz7YTkdmi4bIimVCwi2RCwS6SCQW7SCYU7CKZmMKSzenXl4Kkx8KywSD9BAANKUNlSxOjTqdS+t1gimuQ0lwA7DW3qeK+I0g7NmQq6GLhkrB9QNJA7LxHyTNWusuW2R5U8YjMaMlmlt4akNCoSOqtJstwI1h2mZZjF0GqV0s2i4iCXSQTCnaRTCjYRTKhYBfJhIJdJBMKdpFMTHbJZptDv7OYbO8M4qmDwzJWWqJKlgcmU/9GGWGWR6824in8apIvZtMSR6/ZrG+sNJiV79bkFiqD5z6YJyWsvfi8sRLYaLnqzoCUqJL7hU01Paji81YEJbAFuZe7dfp+KPx8ui3cq4h8bCjYRTKhYBfJhIJdJBMKdpFMKNhFMqFgF8nERPPsc3Ufi6dfSrbTnHA/nRtlSwfXnTiXXZLpnIt+0M6WVF4Lps8G0HTj2uo2uXK2JHMR1OkDQFWSKZdZ7fVaeqrq+R6bCnr0OQYAxNeFjcsgcwiw591l8ysE9yvpGrqDxWSb8uwiomAXyYWCXSQTCnaRTCjYRTKhYBfJhIJdJBMTzbMX7/bQfeWZ4BfI9kFbQ/LoVU2WVSb1zeHRSY6/IPXs0bzvANA582a8fXR8sm+sno7b2XLTC/Gc+fWxY+ldz8fjC6oFMmc9y5V3wjsm3LbosfEJ8f3Cxi+EeXyS4+/0030Px1yEewVgZlea2S/M7AUze97MvjZ8fMnMHjOzl4df97J9icj07OTP+BrAN9z9WgB/CuCrZnYtgLsBPO7u1wB4fPiziMwoGuzuftLdnxl+fxbAiwAuB3ALgMPDXzsM4NZd6qOIjMFH+oDOzK4G8BkAvwSw391PDpveArA/sc1BM1sxs5X/fudcm76KSAs7DnYzmwfwUwBfd/f3zQzp7g7At9vO3Q+5+7K7L198wZ5WnRWR0e0o2M1sDzYD/Ufu/rPhw6fM7MCw/QAA8rGuiEwTTb2ZmQG4H8CL7v7tLU2PALgDwH3Drw/zwzkKBCmJYHpdAEBQVlhsrJFtyevaRjyNdROUuBYVmdKYlMAW6yQ1NyBpwyitSFJvDdk3fW7kvIeVoCwtSNtJ+mw9XV5LrwkpeSaZO36/Bc2sLLnZSKeZPTgnO8mzfxbAlwE8Z2ZHho/dg80g/4mZ3QngNQC37WBfIjIlNNjd/UkAqRXePzfe7ojIbtFwWZFMKNhFMqFgF8mEgl0kEwp2kUxMtMQVZYV63xXpdpY3DfLJTRWXmdLEKCm3RM0SqwEyHTNtj6axBsKcMZsSuVgg0zmT0uBiNZ4mO8rTN934mrEpthuylHWUK29Inh3lJXE7eZ8sSMl0VCJbd+PnNZhPlxV7NBYl3KuIfGwo2EUyoWAXyYSCXSQTCnaRTCjYRTKhYBfJxGTz7O7hMrusjjec9vjSq+JtWb55fS3ePnpdJPliOk11n9Rts3r2hcV0G6sJZ/lgMo11/ebr8e5fT09FVnw63BQFGdtQ9NkU3emmsojPaU1y/EVDxh+w+RXCsRXxNamadLsFT1rv7CKZULCLZELBLpIJBbtIJhTsIplQsItkQsEukonJ5tn7PeClI+n2inRnLZ1XLVgumtSMN6w++fTxdNtivGxxcyaYvxwA5uPlplmdP4J554v1eD78mrQ3a+/Gx2ZDCIJy9878qXDbcvHZsL0+E69LUgTnrVjaF25bsVp6Nj6Bja0I5glgy2B3guEFxblgv3GPROTjQsEukgkFu0gmFOwimVCwi2RCwS6SCQW7SCZ2sj77lQB+CGA/AAdwyN2/a2b3AvgbAG8Pf/Ued3802lfTO4f+kTeCdtLZoCS9bn4Tbktf1diZCMrCi2587DpOZaPunQ3bC7oWeDpfzVL0rG9smXFmPV3OjvJX8bZLG78O2xvS9+iaVpf8b7xvkiYn5ezxuvRAeEOW++LxA/V6emMfpMdF7GRQTQ3gG+7+jJldBOBpM3ts2PYdd/+HHexDRKZsJ+uznwRwcvj9WTN7EcDlu90xERmvj/RHmpldDeAzAH45fOguM3vWzB4ws72JbQ6a2YqZrayeb9dZERndjoPdzOYB/BTA1919HcD3AHwKwHXYfOf/1nbbufshd1929+WlufYdFpHR7CjYzWwPNgP9R+7+MwBw91Puft7dGwDfB3D97nVTRNqiwW5mBuB+AC+6+7e3PH5gy699EcDR8XdPRMZlJ5/GfxbAlwE8Z2ZHho/dA+B2M7sOm+m4YwC+wnZUvwuceTndTjNMQVubbXeyfTQhM9s3ydK0HuwQZYnIRNK0vWj5OUv03OPJvYEmuFfaKk7E7STzRu8X+tyCtgIebruG55Nt0eXayafxTwKwbZrCnLqIzBaNoBPJhIJdJBMKdpFMKNhFMqFgF8mEgl0kExOdSroGsBoMmS2rePveO/G+I5OdM/v9WCUmy8myV+Toue/2+IM27xZrpJ1UPNNjR+3kVqP3E7Ob4zZ6tid9XA+WRCf7FZGPCQW7SCYU7CKZULCLZELBLpIJBbtIJhTsIpkw97h2dqwHM3sbwGtbHtoHgKxnPDWz2rdZ7Regvo1qnH37hLv/3nYNEw32Dx3cbMXdl6fWgcCs9m1W+wWob6OaVN/0Z7xIJhTsIpmYdrAfmvLxI7Pat1ntF6C+jWoifZvq/9lFZHKm/c4uIhOiYBfJxFSC3cxuMrP/NLNXzOzuafQhxcyOmdlzZnbEzFam3JcHzOy0mR3d8tiSmT1mZi8Pv267xt6U+navmZ0YnrsjZnbzlPp2pZn9wsxeMLPnzexrw8eneu6Cfk3kvE38/+xmNgfgvwD8BYDjAJ4CcLu7vzDRjiSY2TEAy+4+9QEYZvZnADYA/NDd/3D42N8DWHX3+4YvlHvd/W9npG/3AtiY9jLew9WKDmxdZhzArQD+GlM8d0G/bsMEzts03tmvB/CKu7/q7gMAPwZwyxT6MfPc/QkAqx94+BYAh4ffH8bmzTJxib7NBHc/6e7PDL8/C+C9Zcaneu6Cfk3ENIL9cgBvbPn5OGZrvXcH8HMze9rMDk67M9vY7+4nh9+/BWD/NDuzDbqM9yR9YJnxmTl3oyx/3pY+oPuwG9z9jwF8AcBXh3+uziTf/D/YLOVOd7SM96Rss8z4b03z3I26/Hlb0wj2EwCu3PLzFcPHZoK7nxh+PQ3gIczeUtSn3ltBd/j19JT781uztIz3dsuMYwbO3TSXP59GsD8F4Boz+6SZVQC+BOCRKfTjQ8zswuEHJzCzCwF8HrO3FPUjAO4Yfn8HgIen2Jf3mZVlvFPLjGPK527qy5+7+8T/AbgZm5/I/xrA302jD4l+/T6A/xj+e37afQPwIDb/rDuHzc827gRwMYDHAbwM4N8BLM1Q3/4ZwHMAnsVmYB2YUt9uwOaf6M8CODL8d/O0z13Qr4mcNw2XFcmEPqATyYSCXSQTCnaRTCjYRTKhYBfJhIJdJBMKdpFM/B8KfxoZmyp1qAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Creation(CNN)"
      ],
      "metadata": {
        "id": "qGqONTpS_AE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a convolutional neural network\n",
        "class EquipmentActivities(nn.Module):\n",
        "  \"\"\"\n",
        "  Model architecture that replicates the TinyVGG\n",
        "  model from CNN explainer website.\n",
        "  \"\"\"\n",
        "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "    super().__init__()\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "        # Create a conv layer - https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
        "        nn.Conv2d(in_channels=input_shape, \n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1), # values we can set ourselves in our NN's are called hyperparameters\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "\n",
        "        # Where did this in_features shape come from? \n",
        "        # It's because each layer of our network compresses and changes the shape of our inputs data.\n",
        "        nn.Linear(in_features=hidden_units*7*7, # there's a trick to calculating this...\n",
        "                  out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv_block_1(x)\n",
        "    # print(f\"Output shape of conv_block_1: {x.shape}\")\n",
        "    x = self.conv_block_2(x) \n",
        "    # print(f\"Output shape of conv_block_2: {x.shape}\")\n",
        "    x = self.classifier(x)\n",
        "    # print(f\"Output shape of classifier: {x.shape}\")\n",
        "    x = torch.sigmoid(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "yUqrp-ES_A2f"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup device agnostic"
      ],
      "metadata": {
        "id": "r46LV-mb_GK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device-agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9a-wAli-_KV0",
        "outputId": "f8e5b6e4-37c0-45fd-b01a-f8cbdbade391"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Model Instance"
      ],
      "metadata": {
        "id": "IHK15nJL_MO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets create model instance\n",
        "torch.manual_seed(42)\n",
        "CNN_Model = EquipmentActivities(input_shape=3,\n",
        "                              hidden_units=10,\n",
        "                              output_shape=len(label)).to(device)"
      ],
      "metadata": {
        "id": "52pkQNiB_P2z"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check Model Summary"
      ],
      "metadata": {
        "id": "IVayjGsd_d0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(CNN_Model, (3, 28, 28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slMpbrn2_gRz",
        "outputId": "64481fa1-6f50-4d8d-c57d-50bbd54da7da"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 10, 28, 28]             280\n",
            "              ReLU-2           [-1, 10, 28, 28]               0\n",
            "            Conv2d-3           [-1, 10, 28, 28]             910\n",
            "              ReLU-4           [-1, 10, 28, 28]               0\n",
            "         MaxPool2d-5           [-1, 10, 14, 14]               0\n",
            "            Conv2d-6           [-1, 10, 14, 14]             910\n",
            "              ReLU-7           [-1, 10, 14, 14]               0\n",
            "            Conv2d-8           [-1, 10, 14, 14]             910\n",
            "              ReLU-9           [-1, 10, 14, 14]               0\n",
            "        MaxPool2d-10             [-1, 10, 7, 7]               0\n",
            "          Flatten-11                  [-1, 490]               0\n",
            "           Linear-12                    [-1, 2]             982\n",
            "================================================================\n",
            "Total params: 3,992\n",
            "Trainable params: 3,992\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.32\n",
            "Params size (MB): 0.02\n",
            "Estimated Total Size (MB): 0.35\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some Helper Function"
      ],
      "metadata": {
        "id": "tt-se7WO_kmQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To compute traning time"
      ],
      "metadata": {
        "id": "YNDbBveZACHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find Computational time\n",
        "from timeit import default_timer as timer \n",
        "def print_train_time(start: float,\n",
        "                     end: float, \n",
        "                     device: torch.device = None):\n",
        "  \"\"\"Prints difference between start and end time.\"\"\"\n",
        "  total_time = end - start\n",
        "  print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
        "  return total_time"
      ],
      "metadata": {
        "id": "2_D-odWY_oEm"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To calculate accuray (Method 1)"
      ],
      "metadata": {
        "id": "BhzTcEfaAIPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy (a classification metric)\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "    \"\"\"Calculates accuracy between truth labels and predictions.\n",
        "\n",
        "    Args:\n",
        "        y_true (torch.Tensor): Truth labels for predictions.\n",
        "        y_pred (torch.Tensor): Predictions to be compared to predictions.\n",
        "\n",
        "    Returns:\n",
        "        [torch.float]: Accuracy value between y_true and y_pred, e.g. 78.45\n",
        "    \"\"\"\n",
        "    correct = torch.eq(y_true, y_pred).sum().item()\n",
        "    acc = (correct / len(y_pred)) * 100\n",
        "    return acc"
      ],
      "metadata": {
        "id": "gpkYRxZv_vHx"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To calculate accuray (Method 2)"
      ],
      "metadata": {
        "id": "ubt6w9crAPmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(model, data_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            outputs = model(images)\n",
        "            predicted = (outputs > 0.5).float()  # Use threshold of 0.5 to convert probabilities to binary predictions\n",
        "            total += labels.size(0) * labels.size(1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "-ghsmNgbAQtv"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop"
      ],
      "metadata": {
        "id": "IwWgAFKwAWe8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Train Loop Function\n",
        "\n",
        "def train_step(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               accuracy_fn: accuracy_fn,\n",
        "               device: torch.device=device\n",
        "               ):\n",
        "  \"\"\" Performs a training with model trying to learn on data_loader\"\"\"\n",
        "  \n",
        "  train_loss, train_acc = 0, 0\n",
        "\n",
        "  # Put model into training mode\n",
        "  model.train()\n",
        "\n",
        "  for batch, (X, y) in enumerate(data_loader):\n",
        "\n",
        "    # Send to the GPU\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # 1. Forward pass\n",
        "    y_pred = model(X)\n",
        "    # y_pred = sigmoid(y_pred)\n",
        "\n",
        "    # 2. Loss calculation\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss +=loss\n",
        "    train_acc += accuracy_fn(y_true=y, y_pred=y_pred) # Go from logits -> pred labels\n",
        "    train_accuracy = get_accuracy(model, data_loader)\n",
        "\n",
        "    # 3. Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss Backward\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Optimizer Step\n",
        "    optimizer.step()\n",
        "\n",
        "  # Calculate loss and accuracy per epoch and print out what's happening\n",
        "  train_loss /= len(data_loader)\n",
        "  train_acc /= len(data_loader)\n",
        "\n",
        "  print(f\"Train Loss: {train_loss: .4f}  |  Train Accuracy: {train_acc: .2f}%\")"
      ],
      "metadata": {
        "id": "L1dNWGNKAZ-2"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Loop"
      ],
      "metadata": {
        "id": "4WejPTafAeVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Test Loop Function\n",
        "\n",
        "def test_step(model: torch.nn.Module,\n",
        "              data_loader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              accuracy_fn: accuracy_fn,\n",
        "              device: torch.device=device):\n",
        "  \n",
        "  # Initial loss and accuaracy\n",
        "  test_loss, test_acc = 0, 0\n",
        "  \n",
        "  # Put the model into evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  # Open and make prediction with inference mode\n",
        "  with torch.inference_mode():\n",
        "    for X, y in data_loader:\n",
        "      # Send data to the device\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      # 1. Forward pass\n",
        "      test_pred = model(X)\n",
        "\n",
        "      # Calculate loss and accuracy\n",
        "      test_loss += loss_fn(test_pred, y)\n",
        "      test_acc += accuracy_fn(y_true = y, y_pred = test_pred) # Go from logits -> pred labels\n",
        "\n",
        "    # Adjust average loss and accuracy\n",
        "    test_loss /= len(data_loader)\n",
        "    test_acc /= len(data_loader)\n",
        "\n",
        "    print(f\"Test Loss: {test_loss: .4f}  |  Test Accuracy: {test_acc: .2f}%\")"
      ],
      "metadata": {
        "id": "ySSR3eO1AiED"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set loss function and optimizer"
      ],
      "metadata": {
        "id": "D9ZYnOpFAzbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=CNN_Model.parameters(),\n",
        "                            lr=0.001)"
      ],
      "metadata": {
        "id": "8yJtSXHpA2ln"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "krOqgxsoAlZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import tqdm for progress bar\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Measure time\n",
        "from timeit import default_timer as timer\n",
        "train_time_start_on_gpu = timer()\n",
        "\n",
        "# Let's define epoch numbers\n",
        "epochs = 10\n",
        "\n",
        "# Create a optimiation and evaluation loop using tran_step() and test_step()\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\\n----------\")\n",
        "\n",
        "  train_step(model = CNN_Model,\n",
        "             data_loader = train_dataloader,\n",
        "             loss_fn = loss_fn,\n",
        "             optimizer = optimizer,\n",
        "             accuracy_fn = accuracy_fn)\n",
        "  \n",
        "\n",
        "  test_step(model = CNN_Model,\n",
        "             data_loader = test_dataloader,\n",
        "             loss_fn = loss_fn,\n",
        "             accuracy_fn = accuracy_fn)\n",
        "  \n",
        "train_time_end_on_gpu = timer()\n",
        "\n",
        "total_train_time_model_1 = print_train_time(start=train_time_start_on_gpu,\n",
        "                                            end = train_time_end_on_gpu,\n",
        "                                            device = device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798,
          "referenced_widgets": [
            "26e8d81d8973495291d95f52deec6aa5",
            "f23a6b9e12d343c8979e000f4ec301c5",
            "91b8bf1411ff4ce2b9bdb1b7ac5f8194",
            "d074268ad4a44012ac39cea7a1ca85b9",
            "0133be5fe5304555baa6ac4e121ed75e",
            "3866a36370c047beaaa92ef866d0cfa1",
            "6792fb5fd1e549178571326f15396416",
            "e11a864a0ae34f15a15ec571eadbcff1",
            "ecd2efa32191450b8cadc86e663e0f00",
            "33e645dc598e441d9202f3c81ba1fb71",
            "4ceafc80f3664962a61ab134c14cec79"
          ]
        },
        "id": "MIqC79wrAo2j",
        "outputId": "7c21b9da-b148-49af-e66d-16814e355670"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26e8d81d8973495291d95f52deec6aa5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "----------\n",
            "Train Loss:  1.3863  |  Train Accuracy:  0.00%\n",
            "Test Loss:  1.3863  |  Test Accuracy:  0.00%\n",
            "Epoch: 1\n",
            "----------\n",
            "Train Loss:  1.3863  |  Train Accuracy:  0.00%\n",
            "Test Loss:  1.3863  |  Test Accuracy:  0.00%\n",
            "Epoch: 2\n",
            "----------\n",
            "Train Loss:  1.3863  |  Train Accuracy:  0.00%\n",
            "Test Loss:  1.3863  |  Test Accuracy:  0.00%\n",
            "Epoch: 3\n",
            "----------\n",
            "Train Loss:  1.3863  |  Train Accuracy:  0.00%\n",
            "Test Loss:  1.3863  |  Test Accuracy:  0.00%\n",
            "Epoch: 4\n",
            "----------\n",
            "Train Loss:  1.3863  |  Train Accuracy:  0.00%\n",
            "Test Loss:  1.3863  |  Test Accuracy:  0.00%\n",
            "Epoch: 5\n",
            "----------\n",
            "Train Loss:  1.3863  |  Train Accuracy:  0.00%\n",
            "Test Loss:  1.3863  |  Test Accuracy:  0.00%\n",
            "Epoch: 6\n",
            "----------\n",
            "Train Loss:  1.3863  |  Train Accuracy:  0.00%\n",
            "Test Loss:  1.3863  |  Test Accuracy:  0.00%\n",
            "Epoch: 7\n",
            "----------\n",
            "Train Loss:  1.3863  |  Train Accuracy:  0.00%\n",
            "Test Loss:  1.3863  |  Test Accuracy:  0.00%\n",
            "Epoch: 8\n",
            "----------\n",
            "Train Loss:  1.3863  |  Train Accuracy:  0.00%\n",
            "Test Loss:  1.3863  |  Test Accuracy:  0.00%\n",
            "Epoch: 9\n",
            "----------\n",
            "Train Loss:  1.3863  |  Train Accuracy:  0.00%\n",
            "Test Loss:  1.3863  |  Test Accuracy:  0.00%\n",
            "Train time on cpu: 19.560 seconds\n"
          ]
        }
      ]
    }
  ]
}